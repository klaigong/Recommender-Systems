{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Recommender systems: Content-based filtering\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the fundamentals of recommendation systems, focusing specifically on content-based filtering techniques. We will delve into the workings of content-based filtering, a method that recommends items similar to those a user has liked or interacted with in the past."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "- Understand the purpose and basic operation of a recommender system\n",
    "- Understand the role of similarity metrics utilised in recommender algorithms\n",
    "- Assess the performance of a recommender system\n",
    "- Implement a simple content-based filtering algorithm\n",
    "\n",
    "## Outline\n",
    "\n",
    "This notebook is structured as follows:\n",
    "- The importance of making recommendations;\n",
    "- Measuring similarity; \n",
    "- Assessing the performance of a recommender system; \n",
    "- The intuition behind content-based filtering; and \n",
    "- Implementation of content-based filtering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The importance of making recommendations\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Long_tail_problem.jpg\"\n",
    "     alt=\"The Long Tail Problem\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "The Long tail problem is often experienced by content distributors. \n",
    "</div>\n",
    "\n",
    "\n",
    "We exist in a technological era where there is far too much content (movies, news articles, shopping products, websites, etc.) for individual items to receive our consideration. For example, consider that the average Google search returns well over 1 million results, yet when was the last time you looked at the websites past the [first page](https://backlinko.com/google-ctr-stats)?  This fact is often illustrated by what is known as the \"long tail problem\" (represented in the figure above), where tracking user engagement with items in a large content repository sees a small number of these items receiving a disproportionate amount of attention. In contrast, the majority of items remain unexplored. The truth is that a user doesn't know of each item that exists, nor has the time to inspect each item even if it were known. \n",
    "\n",
    "In light of the above challenge, a natural question for service providers becomes: \"How do I ensure that an individual is shown a manageable portion of the total content I have available while also ensuring that this content is relevant to and desired by them?\" This question turns out to be extremely valuable, both economically and within society. Luckily for us, decades of hard work by very intelligent individuals have largely answered this question through a collection of algorithms and computing techniques known as recommender systems.\n",
    "\n",
    "\n",
    "Simply put, a recommender system functions by predicting a user’s rating or preference for an item. This allows a service provider to build up a catalogue of items it believes the user will want to examine, thereby increasing their engagement with the service and allowing a wider array of content to be considered.\n",
    "\n",
    "\n",
    "Within this train, we will review some fundamental concepts upon which recommender systems operate. We will also learn how to implement one of the two dominant methods currently studied in relation to recommender systems, referred to as content-based filtering. \n",
    "\n",
    "Let's dive in!  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology: Users, items, and ratings  \n",
    "\n",
    "The first thing we need to do when discussing recommender systems is to clarify some terminology. A recommender system has two primary sets of entities: the users and the items.\n",
    "\n",
    "As we’d expect, **an item is consumed**. It can be watched, read, bought, clicked on, or considered. Items are passive, meaning that their properties or nature do not change.\n",
    "\n",
    "**Users are individuals who interact with the items in a recommendation system.  Users create ratings for specific items within a recommendation system through their actions.** Ratings can be either *explicit* (such as giving your favourite movie 5/5 stars on a review) or *implicit* (such as watching a movie; even though you haven't rated it directly, by viewing something, you indicate that you have some interest in it). Within this train, we only consider explicit ratings, but many of the principles covered here will also apply to implicit ratings.\n",
    "\n",
    "A given user can have ratings for many items in the system or none at all. Generally, as a user continues to interact with a recommender system, it can capture her preferences and ratings for items more easily."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring similarity \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Cosine_similarity.jpg\"\n",
    "     alt=\"Cosine Similarity \"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Measuring the similarity between the ratings of two users (A) and (B) for the books 'Harry Potter and the Philosopher's Stone' and 'The Diary of a Young Girl', using the Cosine similarity metric.  \n",
    "</div>\n",
    "\n",
    "\n",
    "Having learnt about the entities which exist within recommender systems, we may wonder how they function. While this is something we’ll learn throughout this entire train, one fundamental principle we need to understand is that recommender systems are built up by utilising the _existing relations_ between items and users. As such, these systems always require a mechanism to measure how related or _similar_ a user is to another user or an item is to another item. \n",
    "\n",
    "We accomplish this similarity measurement through, you guessed it, a _similarity metric_.  \n",
    "\n",
    "Generally speaking, a similarity metric can be considered the inverse of a distance measure. If two things are considered very similar, they should be assigned a high similarity value (close to 1), while dissimilar items should receive a low similarity value (close to zero).  Other [important properties](https://online.stat.psu.edu/stat508/lesson/1b/1b.2/1b.2.1) include:\n",
    " - (Symmetry) $Sim(A,B) = Sim(B,A)$ \n",
    " - (Identity) $Sim(A,A) = 1$\n",
    " - (Uniqueness) $Sim(A,B) = 1 \\leftrightarrow A = B$\n",
    " \n",
    "While there are many similarity metrics to choose from when building a recommender system (and more than one can certainly be used simultaneously), a popular choice is the **Cosine similarity**. We won't go into the fundamental trig here (we hope you remember this from high school), but recall that as an angle becomes smaller (approaching $0^o$), the value of its cosine increases. Conversely, as the angle increases, the cosine value decreases. It turns out that this behaviour makes the cosine of the angle between two p-dimensional vectors desirable as a [similarity metric](https://en.wikipedia.org/wiki/Cosine_similarity) which can easily be computed.\n",
    "\n",
    "Using the figure above to help guide our understanding, the Cosine similarity between two p-dimensional vectors ${A}$ and $B$ can be given as:\n",
    "\n",
    "$$ \\begin{align}\n",
    "Sim(A,B)  &= \\frac{A \\cdot B}{||A|| \\times ||B||} \\\\ \\\\\n",
    "& = \\frac{\\sum_{i=1}^{p}A_{i}B_{i}}{\\sqrt{{\\sum_{i=1}^{p}A_{i}^2}} \\sqrt{\\sum_{i=1}^{p}B_{i}^2}}, \\\\\n",
    "\\end{align} $$ \n",
    "  \n",
    "\n",
    "Let’s work out the cosine similarity using the above example to make things a little more concrete. Here, each vector represents the ratings given by one of two *users*, $A$ and $B$, who have each rated two books (rating#1 $ \\rightarrow r_1$, and rating#2 $ \\rightarrow r_2$). To work out how similar these two users are based on their supplied ratings, we can use the Cosine similarity definition as follows:   \n",
    "\n",
    "\n",
    "$$ \\begin{align}\n",
    "Sim(A,B)  & = \\frac{(A_{r1} \\times B_{r1})+(A_{r2} \\times B_{r2})}{\\sqrt{A_{r1}^2 + A_{r2}^2} \\times \\sqrt{B_{r1}^2 + B_{r2}^2}} \\\\ \\\\\n",
    "& = \\frac{(3 \\times 5) + (4 \\times 2)}{\\sqrt{9 + 16} \\times \\sqrt{25 + 4}} \\\\ \\\\\n",
    "& = \\frac{23}{26.93} \\\\ \\\\\n",
    "& = 0.854\n",
    "\\end{align} $$\n",
    "\n",
    "It would be a pain to work this out manually each time! Thankfully, we can obtain the same result using the `cosine_similarity` function provided to us in `sklearn`. \n",
    "\n",
    "As usual, before we can go ahead and use this function, we need to import the libraries that we will need.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our regular old heroes \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp # <-- The sister of Numpy, used in our code for numerical efficiency. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entity featurization and similarity computation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Libraries used during sorting procedures.\n",
    "import operator # <-- Convenient item retrieval during iteration \n",
    "import heapq # <-- Efficient sorting of large lists\n",
    "\n",
    "# Imported for our sanity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85419856]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[3,4]]) # <-- Rating vector A\n",
    "B = np.array([[5,2]]) # <-- Rating vector B\n",
    "cosine_similarity(A,B) # Sim(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an understanding of similarity out of the way, let's look at one more important concept before creating our own simple recommender systems - performance measurement!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the performance of a recommender system\n",
    "\n",
    "One more thing we need to consider before diving into the inner workings of recommender system algorithms is how to evaluate their performance. After all, how can you tell if a recommendation is good if the suggested item is something you've never seen before? \n",
    "\n",
    "One straightforward approach is to use a statistical method such as [A/B testing](https://en.wikipedia.org/wiki/A/B_testing), where two very similar users are shown different recommendations, with user ***A*** being shown randomly selected items from our catalogue and user ***B*** being shown recommendations generated by our algorithm. Unfortunately, like other areas of machine learning, this strategy may be too risky/expensive to expose users to a poor recommendation system (or random recommendations!). Instead, in a similar approach to other machine learning fields, we use historical rating data from users to test our systems. As we have seen before, we partition our historical rating data into train and test splits, using train data to help build and tune our recommendation algorithms. In contrast, test data are withheld when performing assessments.\n",
    "In this sense, there are two main variants of metrics which we use to evaluate the predictions made by a recommender system:\n",
    "\n",
    "#### Objective measures\n",
    "\n",
    "Objective performance measures for a recommendation system provide results that do not depend upon personal interpretation to assign success. These measures tend to focus on actual preferences/ratings given by users to items and are compared against ratings/preferences predicted by an algorithm. Common examples of objective measures include:\n",
    "\n",
    "\n",
    "   - **Single-value metrics:** These are quantities we've seen before, such as RMSE and MAE, which measure the error between a known and predicted rating on a continuous scale.\n",
    "    \n",
    "    \n",
    "   - **Catalog-based metrics:** These are measures of performance computed over lists of recommended items generated for a user. They mainly consist of variations surrounding what is known as the *hit rate*, which determines the number of highly rated items appearing in a recommendation list that the user has actually given a high rating to.    \n",
    "   \n",
    " \n",
    " - **Coverage:** This metric is calculated across multiple user recommendation lists and returns the number of users who received at least one high-rated recommendation on their list. \n",
    " \n",
    "#### Subjective measures\n",
    "\n",
    "In contrast to objective performance measures, subjective metrics provide quantitative values that must be interpreted to determine success. These measures typically capture characteristics of recommendations that are not directly related to rating data, but that may nonetheless be very important when a user decides whether or not to follow a suggestion. Two popular measures are:   \n",
    " \n",
    " - **Novelty:** This is a measure of how many underrated items (not to be confused with poorly rated ones) are suggested to a user. As we have already discussed, exposing individuals to lesser-known items in a catalogue is vital to a recommender system’s functioning.\n",
    " \n",
    " \n",
    " - **Diversity:** This measurement evaluates the number of different item categories present in a recommendation list given to a user. \n",
    " \n",
    " \n",
    "We’re done with the background theory for now; let’s go and build something!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Producing book recommendations \n",
    "\n",
    "To ground our learning in a practical problem, we'll be using the [Goodbooks-10k dataset](http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/) within this train. \n",
    "\n",
    "[Goodbooks](https://www.goodbooks.io/)  is an online book recommendation service that pairs readers with their next favourite read. Our dataset contains information on 10,000 books from the service’s catalogue, along with ~80,000 reviews generated by site visitors. We’ll use this rich information to try our best to recommend what good books you (or your friends/family) should read next.\n",
    "\n",
    "\n",
    "### Dataset overview: Brief EDA\n",
    "\n",
    "We'll be making use of two main files derived from the dataset$^*$;\n",
    " \n",
    " - **Books_with_tags.csv**: We created this file for the convenience of this train. It contains book_id, title, author, date, etc. data from the original ***books.csv*** file, along with user tags merged from the ***book_tags.csv*** and ***tags.csv*** files. \n",
    " \n",
    " \n",
    " - **Book_ratings.csv**: This is a subset of the ***ratings.csv*** file, with a field for the book titles added for convenience. This file contains the important mapping between users and item ratings.\n",
    " \n",
    "The full dataset can be found [here](https://www.kaggle.com/zygmunt/goodbooks-10k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "      <td>to-read fantasy favorites currently-reading yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPrÃ©</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "      <td>to-read fantasy favorites currently-reading yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "      <td>to-read fantasy favorites currently-reading yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "\n",
       "                        authors  original_publication_year  \\\n",
       "0               Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPrÃ©                     1997.0   \n",
       "2               Stephenie Meyer                     2005.0   \n",
       "\n",
       "                             original_title  ... work_ratings_count  \\\n",
       "0                          The Hunger Games  ...            4942365   \n",
       "1  Harry Potter and the Philosopher's Stone  ...            4800065   \n",
       "2                                  Twilight  ...            3916824   \n",
       "\n",
       "  work_text_reviews_count  ratings_1  ratings_2  ratings_3  ratings_4  \\\n",
       "0                  155254      66715     127936     560092    1481305   \n",
       "1                   75867      75504     101676     455024    1156318   \n",
       "2                   95009     456191     436802     793319     875073   \n",
       "\n",
       "   ratings_5                                          image_url  \\\n",
       "0    2706317  https://images.gr-assets.com/books/1447303603m...   \n",
       "1    3011543  https://images.gr-assets.com/books/1474154022m...   \n",
       "2    1355439  https://images.gr-assets.com/books/1361039443m...   \n",
       "\n",
       "                                     small_image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603s...   \n",
       "1  https://images.gr-assets.com/books/1474154022s...   \n",
       "2  https://images.gr-assets.com/books/1361039443s...   \n",
       "\n",
       "                                            tag_name  \n",
       "0  to-read fantasy favorites currently-reading yo...  \n",
       "1  to-read fantasy favorites currently-reading yo...  \n",
       "2  to-read fantasy favorites currently-reading yo...  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/books_with_tags.csv')\n",
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books in dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "print (f'Number of books in dataset: {books.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1169</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id                                              title  rating\n",
       "0      314        1  Harry Potter and the Half-Blood Prince (Harry ...       5\n",
       "1      439        1  Harry Potter and the Half-Blood Prince (Harry ...       3\n",
       "2      588        1  Harry Potter and the Half-Blood Prince (Harry ...       5\n",
       "3     1169        1  Harry Potter and the Half-Blood Prince (Harry ...       4\n",
       "4     1185        1  Harry Potter and the Half-Blood Prince (Harry ...       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_ratings = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/book_ratings.csv')\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings in dataset: 79701\n"
     ]
    }
   ],
   "source": [
    "print (f'Number of ratings in dataset: {book_ratings.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the ratings given by users. Here, we see that readers generally are on the kinder end of the rating spectrum, with a far higher proportion of positive reviews (> 3) being given over negative ones (< 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating in dataset: 3.8616453996813087\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1011.11x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with sns.axes_style('white'):\n",
    "    g = sns.catplot(data=book_ratings, x=\"rating\", y=None, aspect=2.0, kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\")\n",
    "print (f'Average rating in dataset: {np.mean(book_ratings[\"rating\"])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's enough spelunking through our data. Let’s go ahead and make a recommendation system.\n",
    "\n",
    "The first step is generating recommendations using content-based filtering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 800px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Content_filtering.jpg\"\n",
    "     alt=\"Content-based Filtering\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=800px/>\n",
    "A depiction of the decision process used to recommend items within content-based filtering algorithms.  \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Content-based filtering, we seek to make recommendations based on **how similar an item's properties or features are to those of other items.**\n",
    "\n",
    "Let's use the image above to help us see how this works. Mpho is an avid reader who has just finished the novel \"The Golden Compass\". Besides the written contents inside this book (item), it has certain attributes or properties which further describe it - such as the author (\"Philip Pullman\"), genre (\"fantasy\"), or target audience (\"young adult\"). These properties are not unique to this novel, as other books also have authors, genres, target audiences, etc. As such, we can compare the properties of different books with the assumption that books which have properties in common (such as author or genre) are similar to one another. We can further **assume that individuals like similar items**. For our example, this means that Mpho, if using content-based filtering to recommend her next book, would have a book such as \"Harry Potter and the Philosopher's Stone\" suggested to her over Anne Frank's \"The Diary of a Young Girl\", as the former novel is far more 'similar' to The Golden Compass.     \n",
    "\n",
    "So let's see how we would implement a system like this in real life."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation \n",
    "\n",
    "Let's implement a straightforward content filtering-based recommendation algorithm.\n",
    "\n",
    "To begin, we need to gather the various properties of our items so that we can convert them into meaningful features. Following along from our example above, we're going to use the `tag_name` field for each book as a representation of properties such as genre, time-period, and target audience. We're also going to consider the `authors` field, as individuals often enjoy reading novels written by the same author. \n",
    "\n",
    "We start off by creating a new column in our `books` dataframe called `auth_tags`, which contains the above-motivated contents for each item. We additionally create two pandas series objects to help us translate between book titles and indexes of our dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(books, test_size=0.05, random_state=42)\n",
    "train_data_r, test_data_r = train_test_split(book_ratings, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['auth_tags'] = (pd.Series(books[['authors', 'tag_name']]\n",
    "                      .fillna('')\n",
    "                      .values.tolist()).str.join(' '))\n",
    "\n",
    "# Convenient indexes to map between book titles and indexes of \n",
    "# the books dataframe\n",
    "titles = books['title']\n",
    "indices = pd.Series(books.index, index=books['title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need a mechanism to convert these textual features into a format that enables us to compute their relative similarities. This will allow us to translate our string-based collection of tags and authors into numerical vectors (see [here](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) for an overview of this process which is very similar to [count-based vectorization](https://youtu.be/W9VtEVBdgnQ))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2),\n",
    "                     min_df=0.0, stop_words='english')\n",
    "\n",
    "# Produce a feature matrix, where each row corresponds to a book,\n",
    "# with TF-IDF features as columns \n",
    "tf_authTags_matrix = tf.fit_transform(books['tag_name'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the similarity between each vector within our matrix. This is done by making use of the `cosine_similarity` function provided to us by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_authTags = cosine_similarity(tf_authTags_matrix, \n",
    "                                        tf_authTags_matrix)\n",
    "print (cosine_sim_authTags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.23560979, 0.28324674, ..., 0.05084198, 0.07947133,\n",
       "        0.01691533],\n",
       "       [0.23560979, 1.        , 0.22459026, ..., 0.0530554 , 0.07126569,\n",
       "        0.02330787],\n",
       "       [0.28324674, 0.22459026, 1.        , ..., 0.03356699, 0.04251551,\n",
       "        0.01473002],\n",
       "       [0.1270975 , 0.17922805, 0.11466086, ..., 0.07377326, 0.07659143,\n",
       "        0.05353916],\n",
       "       [0.12639752, 0.16195238, 0.12790219, ..., 0.07104895, 0.09558364,\n",
       "        0.040346  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_authTags[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting structure is a $10000 \\times 10000$ dense similarity matrix $S^I$, where the value of the entry in the $i^{th}$ row and $j^{th}$ column, $S^I_{i,j}$, corresponds to the similarity of books $i$ and $j$ within our dataset.\n",
    "\n",
    "Using this notation, if $i$ and $j$ are the same number (i.e. all the diagonal entries in $S^I$), then the similarity value is equal to 1 (an item is completely similar to itself).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-N recommendations\n",
    "\n",
    "With our content similarity matrix computed, we're now ready to make some recommendations! Let's begin by generating a top-N list of books similar to the one which we prompt the system with.    \n",
    "\n",
    "Following along from our earlier algorithmic explanation, we do this by: \n",
    "\n",
    "  1. Select an initial item (book) from which to generate recommendations. \n",
    "  2. Extract all the similarity values between the initial item and each other item in the similarity matrix.\n",
    "  3. Sort the resulting values in descending order. \n",
    "  4. Select the top N similarity values and return the corresponding item details to the user. This is now our simple top-N list.  \n",
    "  \n",
    "We implement this algorithmic process in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_generate_top_N_recommendations(book_title, N=10):\n",
    "    # Convert the string book title to a numeric index for our \n",
    "    # similarity matrix\n",
    "    b_idx = indices[book_title]\n",
    "    # Extract all similarity values computed with the reference book title\n",
    "    sim_scores = list(enumerate(cosine_sim_authTags[b_idx]))\n",
    "    # Sort the values, keeping a copy of the original index of each value\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Select the top-N values for recommendation\n",
    "    sim_scores = sim_scores[1:N]\n",
    "    # Collect indexes \n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    # Convert the indexes back into titles \n",
    "    return titles.iloc[book_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our function defined, let's test our simple content-based recommender on some sample book titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188     The Lord of the Rings (The Lord of the Rings, ...\n",
       "154            The Two Towers (The Lord of the Rings, #2)\n",
       "160     The Return of the King (The Lord of the Rings,...\n",
       "610              The Silmarillion (Middle-Earth Universe)\n",
       "18      The Fellowship of the Ring (The Lord of the Ri...\n",
       "4975        Unfinished Tales of NÃºmenor and Middle-Earth\n",
       "2308                               The Children of HÃºrin\n",
       "963     J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
       "465                             The Hobbit: Graphic Novel\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_generate_top_N_recommendations(\"The Hobbit\", N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124                       Hamlet\n",
       "769                Julius Caesar\n",
       "352                      Othello\n",
       "153                      Macbeth\n",
       "247    A Midsummer Night's Dream\n",
       "838       The Merchant of Venice\n",
       "529       Much Ado About Nothing\n",
       "854                Twelfth Night\n",
       "386                 The Crucible\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_generate_top_N_recommendations(\"Romeo and Juliet\", N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86                           Night (The Night Trilogy #1)\n",
       "178                    Angela's Ashes (Frank McCourt, #1)\n",
       "512     The Hiding Place: The Triumphant True Story of...\n",
       "799                                  The Story of My Life\n",
       "6546                        I Have Lived a Thousand Years\n",
       "1814    Anne Frank Remembered: The Story of the Woman ...\n",
       "57                     The Adventures of Huckleberry Finn\n",
       "89                                          The Outsiders\n",
       "603                                     Girl, Interrupted\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_generate_top_N_recommendations(\"The Diary of a Young Girl\", N=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen the results of these top-N lists, a couple of observations can be made. \n",
    "\n",
    "- First, our recommendations seem to be strongly centred around the author of the reference book. For example,  other works by Tolkien and Shakespeare are highly recommended when using reference searches for \"The Hobbit\" and \"Romeo and Juliet\" respectively. This could be a natural result of the fact that an author's name is far less common in the dataset than other textual features such as genre. As such, books which share an author will be regarded as being far more similar.  \n",
    "\n",
    "\n",
    " - Second, in cases where the reference author has not written multiple book titles, such as Anne Frank (The Diary of a Young Girl), the recommendations produced are more varied and cover multiple titles in the same or similar genres. \n",
    "\n",
    " \n",
    "Based on these observations, we can ask if, in fact, the recommendations for \"The Hobbit\" and \"Romeo and Juliet\" are actually any good. After all, a reader who knows of Tolkien and Shakespeare will often already know of other books these authors have written as well. This is where some of the subjective metrics introduced earlier (such as diversity), can be used to penalize these recommendations and help discover better ones. \n",
    "\n",
    "---\n",
    "Seeing that we were able to produce more varied recommendations when the author didn't write multiple titles, try to alter the above code cells to calculate similarity only using the `tag_name` field.\n",
    "\n",
    "How does this alteration affect the recommendations produced?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Rating Prediction\n",
    "\n",
    "As motivated previously, in some cases, we may wish to calculate directly what rating a user _would_ give a book that they haven't read yet.\n",
    "\n",
    "We can modify our content-based filtering algorithm to do this in the following manner: \n",
    "\n",
    "   1. Select a reference user from the database and a reference item (book) they have _not_ rated. \n",
    "   2. For the user, gather the similarity values between the reference item and each item the user _has_ rated. \n",
    "   3. Sort the gathered similarity values in descending order. \n",
    "   4. Select the $k$ highest similarity values, which are above a given threshold value, creating a collection $K$. \n",
    "   5. Compute a weighted average rating from these values, which is the sum of the similarity values of each item multiplied by its assigned user rating, divided by the sum of the similarity values. This can be expressed in the formula as:\n",
    "   \n",
    "   $$ \\hat{R}_{ju} = \\frac{\\sum_{i \\in K} s_{ij} \\times r_{iu}}{\\sum_{i \\in K} s_{ij}}   $$\n",
    "   \n",
    "   where $\\hat{R}_{ju}$ is the weighted average computed for the reference item $j$ and reference user $u$, $K$ is the collection of items, $s_{ij}$ is the similarity computed between items $i$ and $j$, and $r_{iu}$ is the known rating user $u$ has given item $i$.\n",
    "   6. We return the weighted average $\\hat{R}_{ju}$ as the prediction for our reference item.\n",
    "   \n",
    "   \n",
    "We implement this algorithmic process in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_generate_rating_estimate(book_title, user, rating_data, k=20, threshold=0.0):\n",
    "    # Convert the book title to a numeric index for our similarity matrix\n",
    "    b_idx = indices[book_title]\n",
    "    neighbors = [] # <-- Stores our collection of similarity values \n",
    "     \n",
    "    # Gather the similarity ratings between each book the user has rated\n",
    "    # and the reference book \n",
    "    for index, row in rating_data[rating_data['user_id']==user].iterrows():\n",
    "        sim = cosine_sim_authTags[b_idx-1, indices[row['title']]-1]\n",
    "        neighbors.append((sim, row['rating']))\n",
    "    # Select the top-N values from our collection\n",
    "    k_neighbors = heapq.nlargest(k, neighbors, key=lambda t: t[0])\n",
    "\n",
    "    # Compute the weighted average using similarity scores and \n",
    "    # user item ratings. \n",
    "    simTotal, weightedSum = 0, 0\n",
    "    for (simScore, rating) in k_neighbors:\n",
    "        # Ensure that similarity ratings are above a given threshold\n",
    "        if (simScore > threshold):\n",
    "            simTotal += simScore\n",
    "            weightedSum += simScore * rating\n",
    "    try:\n",
    "        predictedRating = weightedSum / simTotal\n",
    "    except ZeroDivisionError:\n",
    "        # Cold-start problem - No ratings given by user. \n",
    "        # We use the average rating for the reference item as a proxy in this case \n",
    "        predictedRating = np.mean(rating_data[rating_data['title']==book_title]['rating'])\n",
    "    return predictedRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def content_generate_rating_estimate(title, user, rating_data, k=20, threshold=0.0):\n",
    "    # This is a simplified version of what your function might look like.\n",
    "    # You need to ensure that 'similarity_score' and 'rating' are scalar values.\n",
    "    \n",
    "    neighbors = []\n",
    "    \n",
    "    for index, row in rating_data.iterrows():\n",
    "        if row['user_id'] == user:\n",
    "            continue\n",
    "        # Compute the similarity score between the given 'title' and 'row['title']'\n",
    "        similarity_score = compute_similarity(title, row['title'])  # Ensure this returns a scalar\n",
    "        if similarity_score > threshold:\n",
    "            neighbors.append((similarity_score, row['rating']))\n",
    "    \n",
    "    # Add debug statements to inspect neighbors\n",
    "    # print(f\"Neighbors before heapq.nlargest: {neighbors}\")\n",
    "    \n",
    "    # Select the top-N values from our collection\n",
    "    k_neighbors = heapq.nlargest(k, neighbors, key=lambda t: t[0])\n",
    "    \n",
    "    # Compute the weighted average using similarity scores and user item ratings. \n",
    "    simTotal, weightedSum = 0, 0\n",
    "    for sim, rating in k_neighbors:\n",
    "        simTotal += sim\n",
    "        weightedSum += sim * rating\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    \n",
    "    return weightedSum / simTotal\n",
    "\n",
    "def compute_similarity(title1, title2):\n",
    "    # Dummy similarity computation for illustration.\n",
    "    # Replace with your actual similarity computation logic.\n",
    "    return 1.0 if title1 == title2 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7354, 98, 4979, 7354, 98, 4979, 7354, 98, 4979]\n"
     ]
    }
   ],
   "source": [
    "test_users = test_data_r['user_id'][:3]\n",
    "test_titles = test_data_r['book_id'][:3]\n",
    "\n",
    "ratings = []\n",
    "books = []\n",
    "\n",
    "for user in test_users:\n",
    "    for title in test_titles:\n",
    "        rat = content_generate_rating_estimate(title, user, rating_data=book_ratings, k=20, threshold=0.0)\n",
    "        ratings.append(rat)\n",
    "        books.append(title)\n",
    "\n",
    "print(ratings)\n",
    "print(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m title \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m actual_rating \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_generate_rating_estimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(predicted_rating):\n\u001b[0;32m     14\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_rating)\n",
      "Cell \u001b[1;32mIn[39], line 9\u001b[0m, in \u001b[0;36mcontent_generate_rating_estimate\u001b[1;34m(title, user, rating_data, k, threshold)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontent_generate_rating_estimate\u001b[39m(title, user, rating_data, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# This is a simplified version of what your function might look like.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# You need to ensure that 'similarity_score' and 'rating' are scalar values.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     neighbors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrating_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\klaig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:1542\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1540\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1542\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1544\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\klaig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:586\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m--> 586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m \u001b[43m_get_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.data_manager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    588\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleBlockManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[1;32mc:\\Users\\klaig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:149\u001b[0m, in \u001b[0;36m_get_option\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    146\u001b[0m key \u001b[38;5;241m=\u001b[39m _get_single_key(pat, silent)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m root, k \u001b[38;5;241m=\u001b[39m \u001b[43m_get_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m root[k]\n",
      "File \u001b[1;32mc:\\Users\\klaig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:636\u001b[0m, in \u001b[0;36m_get_root\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_root\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 636\u001b[0m     path \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    637\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m _global_config\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generating predictions\n",
    "predictions = []\n",
    "actual_ratings = []\n",
    "\n",
    "\n",
    "for index, row in test_data_r.iterrows():\n",
    "    user = row['user_id']\n",
    "    title = row['title']\n",
    "    actual_rating = row['rating']\n",
    "    \n",
    "    predicted_rating = content_generate_rating_estimate(title, user, train_data_r, k=20, threshold=0.0)\n",
    "    \n",
    "    if not np.isnan(predicted_rating):\n",
    "        predictions.append(predicted_rating)\n",
    "        actual_ratings.append(actual_rating)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(actual_ratings, predictions))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "mae = mean_absolute_error(actual_ratings, predictions)\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our algorithm defined, let's quickly test it out to see some results. \n",
    "\n",
    "To help us get a sense of the relevance and accuracy of these ratings, we select a lucky user (number 314) and consider their historical data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>314</td>\n",
       "      <td>6</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (Harry Pot...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>314</td>\n",
       "      <td>29</td>\n",
       "      <td>The Mother Tongue: English and How It Got That...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>314</td>\n",
       "      <td>30</td>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>314</td>\n",
       "      <td>36</td>\n",
       "      <td>The Lord of the Rings: Weapons and Warfare</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>314</td>\n",
       "      <td>98</td>\n",
       "      <td>What to Expect the First Year (What to Expect)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>Chapterhouse: Dune (Dune Chronicles #6)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>314</td>\n",
       "      <td>106</td>\n",
       "      <td>Dune Messiah (Dune Chronicles #2)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  book_id                                              title  \\\n",
       "401       314        6  Harry Potter and the Goblet of Fire (Harry Pot...   \n",
       "1500      314       29  The Mother Tongue: English and How It Got That...   \n",
       "1600      314       30  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...   \n",
       "1900      314       36         The Lord of the Rings: Weapons and Warfare   \n",
       "2300      314       98     What to Expect the First Year (What to Expect)   \n",
       "2400      314      105            Chapterhouse: Dune (Dune Chronicles #6)   \n",
       "2501      314      106                  Dune Messiah (Dune Chronicles #2)   \n",
       "\n",
       "      rating  \n",
       "401        5  \n",
       "1500       3  \n",
       "1600       4  \n",
       "1900       4  \n",
       "2300       3  \n",
       "2400       3  \n",
       "2501       4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of ratings from user 314\n",
    "book_ratings[book_ratings['user_id'] == 314][3:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate some ratings for books which user 314 has already rated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - The Lord of the Rings: Weapons and Warfare\n",
      "---\n",
      "Actual rating: \t\t 4\n",
      "Predicted rating: \t 3.8200585934663667\n"
     ]
    }
   ],
   "source": [
    "title = \"The Lord of the Rings: Weapons and Warfare\"\n",
    "actual_rating = book_ratings[(book_ratings['user_id'] == 314) & (book_ratings['title'] == title)]['rating'].values[0]\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t {actual_rating}\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - Survival in Auschwitz\n",
      "---\n",
      "Actual rating: \t\t 2\n",
      "Predicted rating: \t 2.8246814748278624\n"
     ]
    }
   ],
   "source": [
    "title = \"Survival in Auschwitz\"\n",
    "actual_rating = book_ratings[(book_ratings['user_id'] == 314) & (book_ratings['title'] == title)]['rating'].values[0]\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t {actual_rating}\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this process, but now for similar titles which have not been rated:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - The Hobbit\n",
      "---\n",
      "Actual rating: \t\t ?\n",
      "Predicted rating: \t 3.5715015277712188\n"
     ]
    }
   ],
   "source": [
    "title = \"The Hobbit\"\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t ?\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title - Dune (Dune Chronicles #1)\n",
      "---\n",
      "Actual rating: \t\t ?\n",
      "Predicted rating: \t 3.764917447911706\n"
     ]
    }
   ],
   "source": [
    "title = \"Dune (Dune Chronicles #1)\"\n",
    "pred_rating = content_generate_rating_estimate(book_title=title, user=314, rating_data=book_ratings)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t ?\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, our content-based ratings seem to be pretty good - being out by less than 1 rating point per known prediction! While we can't make the same judgement for the predicted ratings of the unseen books, they are close to known book ratings which are similar in nature, which is a promising sign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We covered a lot of ground in this train by identifying the building blocks of recommender systems: items (things) and users (people). We've learned how recommender algorithms fundamentally use similarity to compare these items and users, with item-item similarity represented by the content-based filtering method. We went on to review the content-based filtering method both theoretically and practically through code implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "Links to additional resources to help with the understanding of concepts presented in the train:\n",
    "\n",
    "- [Intro to Recommender Systems](https://www.youtube.com/watch?v=Eeg1DEeWUjA&feature=youtu.be)\n",
    "- [Advanced Recommender System Metrics](https://wiki.epfl.ch/edicpublic/documents/Candidacy%20exam/Evaluation.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
